{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "SOD322-pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjO57ic8x2Wv"
      },
      "source": [
        "# SOD322: Recherche Opérationnelle et Données Massives\n",
        "\n",
        "## Projet\n",
        "\n",
        "Laurent Lam & Ilyes El-Rammach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av17lKdoyBvR"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4diZcVKxrEn"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import ttest_ind, chi2_contingency\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYA1Lr5wyK6G"
      },
      "source": [
        "### Configuration variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhMFYznryNmy"
      },
      "source": [
        "seed = 18\n",
        "np.random.seed(seed)\n",
        "\n",
        "test_size = 1/3\n",
        "\n",
        "bootstrap_size = 1000\n",
        "boot_iter = 1000\n",
        "pval_threshold = 0.05\n",
        "max_bins = 5\n",
        "\n",
        "dataset_path = \"./kidney.csv\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKKSljZJyGxG"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znOV_DmGxrEz"
      },
      "source": [
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "columns = df.columns.tolist()\n",
        "features, target = columns[:-1], columns[-1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dzjul9dyRpO"
      },
      "source": [
        "feature_clf = {'age': 'num', 'bp': 'num', 'sg':'cat', 'al': 'cat', 'su': 'cat', 'rbc': 'cat', 'pc': 'cat', 'pcc': 'cat', 'ba': 'cat', 'bgr': 'num', 'bu': 'num', 'sc': 'num', 'sod': 'num', 'pot': 'num', 'hemo': 'num', 'pcv': 'num', 'wbcc': 'num', 'rbcc': 'num', 'htn': 'cat', 'dm': 'cat', 'cad': 'cat', 'appet': 'cat', 'pe': 'cat', 'ane': 'cat', 'class': 'cat'}\n",
        "label_dict = {'normal': 0, 'abnormal': 1, 'notpresent': 0, 'present': 1, 'yes': 1, 'no': 0, 'ckd': 1, 'notckd': 0, 'good': 0, 'poor':1}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnuFNfmhyVKH"
      },
      "source": [
        "### Preprocess/Format features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb6pKGsxxrE0"
      },
      "source": [
        "def preprocess_columns(df):\n",
        "    processed_features = {}\n",
        "    columns = df.columns.tolist()\n",
        "    for feature in columns:\n",
        "        if df[feature].dtype in [int, float]:\n",
        "            processed_features[feature] = df[feature].tolist()\n",
        "        elif df[feature].dtype == object:\n",
        "            processed_features[feature] = [label_dict[sample] for sample in df[feature]]\n",
        "    return pd.DataFrame(processed_features)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMdjDaxayc92"
      },
      "source": [
        "df_processed = preprocess_columns(df)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR4iD1MYyroY"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ830-ihyxQZ",
        "outputId": "3c38ad38-3c88-4afb-cc6f-96f8506447ce"
      },
      "source": [
        "df_train, df_test = train_test_split(df_processed, test_size=test_size, random_state=seed)\n",
        "print(f\"Training set size: {df_train.shape[0]}\")\n",
        "print(f\"Testing set size: {df_test.shape[0]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: 126\n",
            "Testing set size: 63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqIQZH0717bi"
      },
      "source": [
        "# df_train"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ99H4B617hH"
      },
      "source": [
        "# df_test"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW8A8AelCdsd"
      },
      "source": [
        "## Training split analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXSTf9-KydOQ"
      },
      "source": [
        "### Independant analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o56--vq3ydY9"
      },
      "source": [
        "def test_column_significance(feature, target):\n",
        "    # T-Test\n",
        "    if feature_clf[feature.name] == 'num':\n",
        "        feature_true = feature[target == 1]\n",
        "        feature_false = feature[target == 0]\n",
        "        tval, pval = ttest_ind(feature_true, feature_false)\n",
        "        bt_diff_means = bootstrap_diff_means(feature, target)\n",
        "        diff_means, boot_means, boot_ci = compute_confidence_interval(feature, bt_diff_means)\n",
        "        stat = {'diff_means': diff_means, 'boot_means': boot_means, 'boot_ci': boot_ci, 'tval': tval, 'pval': pval, 'bt_diff_means': bt_diff_means}\n",
        "    # Chi-2 Test\n",
        "    elif feature_clf[feature.name] == 'cat':\n",
        "        contingency_table = pd.concat([feature, target], axis=1).pivot_table(index=feature.name, columns=target.name, aggfunc=len).fillna(0).copy().astype(int)\n",
        "        g, pval, dof, expected = chi2_contingency(contingency_table)\n",
        "        stat = {'g': g, 'pval': pval, 'dof': dof, 'expected': expected, 'cont': contingency_table}\n",
        "    else:\n",
        "        print(f'COLUMN NOT CLASSIFIED IN feature_clf: {feature.name}')\n",
        "    return stat\n",
        "\n",
        "def bootstrap_diff_means(feature, target, sample_size=boot_iter, bt_size=bootstrap_size):\n",
        "    bt_diff_means = []\n",
        "    for bootstrap_iter in range(sample_size):\n",
        "        boot_index = np.random.choice(target.index, size = bt_size)\n",
        "        boot_feature, boot_target = feature[boot_index], target[boot_index]\n",
        "        true_boot_feature = boot_feature[boot_target == 1]\n",
        "        false_boot_feature = boot_feature[boot_target == 0]\n",
        "        bt_diff_means.append(true_boot_feature.mean() - false_boot_feature.mean())\n",
        "    return bt_diff_means\n",
        "\n",
        "def compute_confidence_interval(feature, bt_diff_means):\n",
        "    diff_means = feature.mean()\n",
        "    boot_means = np.mean(bt_diff_means)\n",
        "    boot_ci = np.quantile(bt_diff_means, q=[0.025, 0.975])\n",
        "    return diff_means, boot_means, boot_ci"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIva-E6kxrE1",
        "outputId": "ac29c32d-e877-423a-e559-8df9fa1a2967"
      },
      "source": [
        "res_stats = {}\n",
        "for feature in tqdm(features):\n",
        "    res_stats[feature] = test_column_significance(df_train[feature], df_train[target])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh73OTu5xrE2",
        "outputId": "fa1c48bb-d4e5-43e3-b5c7-88bc94f35772"
      },
      "source": [
        "significant_features = [feature for feature in features if res_stats[feature]['pval'] < pval_threshold]\n",
        "print(f\"Significant features {len(significant_features)}/{len(features)}: \\n{significant_features}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Significant features 22/23: \n",
            "['age', 'bp', 'sg', 'al', 'su', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHvugLLYxrE4"
      },
      "source": [
        "df_train = df_train[significant_features + ['class']]\n",
        "df_test = df_test[significant_features + ['class']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMYc8v-ZztTj"
      },
      "source": [
        "### Relationship Analysis # TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKRuxvN-xrE4"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIb3YyELzx1m"
      },
      "source": [
        "### Categorial variables: Modalities Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFVodYlHxrE4"
      },
      "source": [
        "def get_aggregated_modalities(contingency_table, ineq='zero'):\n",
        "    modalities = contingency_table.index.tolist()\n",
        "    discr = False\n",
        "    aggr = False\n",
        "    aggr_mod = []\n",
        "    aggr_mod_index = []\n",
        "    for modality_index, modality in enumerate(modalities):\n",
        "        if aggr is False:\n",
        "            tmp_mod = []\n",
        "            tmp_mod_index = []\n",
        "        false, true = contingency_table.iloc[modality_index].to_numpy()\n",
        "        if ineq == 'zero':\n",
        "            if aggr is True and (false != 0 and true != 0):\n",
        "                aggr_mod.append(tmp_mod)\n",
        "                aggr_mod_index.append(tmp_mod_index)\n",
        "                tmp_mod = []\n",
        "                tmp_mod_index = []\n",
        "                aggr = False\n",
        "            if false == 0 or true == 0:\n",
        "                aggr = True\n",
        "        tmp_mod.append(modality)\n",
        "        tmp_mod_index.append(modality_index)\n",
        "        if not aggr:\n",
        "            aggr_mod.append(tmp_mod)\n",
        "            aggr_mod_index.append(tmp_mod_index)\n",
        "    if aggr_mod[-1] != tmp_mod:\n",
        "        aggr_mod.append(tmp_mod)\n",
        "        aggr_mod_index.append(tmp_mod_index)\n",
        "    return aggr_mod, aggr_mod_index\n",
        "\n",
        "\n",
        "def compute_aggr_mod_bins(res_stats):\n",
        "    new_mod_bins = {}\n",
        "    for feature in features:\n",
        "        if feature_clf[feature] == 'cat':\n",
        "            if res_stats[feature]['dof'] > 2:\n",
        "                aggregated_mod, aggregated_mod_index = get_aggregated_modalities(res_stats[feature]['cont'])\n",
        "                if len(aggregated_mod) < res_stats[feature]['dof']:\n",
        "                    # new_mod_bins[feature] = [np.min(mod) for mod in aggregated_mod]\n",
        "                    new_mod_bins[feature] = aggregated_mod\n",
        "    return new_mod_bins\n",
        "\n",
        "def reduce_mod_features(df, new_mod_bins):\n",
        "    new_modalities_dict = {}\n",
        "    for feature, mod_bins in new_mod_bins.items():\n",
        "        new_modalities_dict[feature] = {modality: bin_index for bin_index, mod_bin in enumerate(mod_bins) for modality in mod_bin}\n",
        "        df[feature] = df[feature].apply(lambda x: new_modalities_dict[feature][x])\n",
        "    return df, new_modalities_dict"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gh3DL_jxrE5"
      },
      "source": [
        "new_mod_bins = compute_aggr_mod_bins(res_stats)\n",
        "df_train_reprocessed, new_modalities_dict = reduce_mod_features(df_train.copy(deep=True), new_mod_bins)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP-Ur_b3022k"
      },
      "source": [
        "### Continuous variables : Binning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0_JVsb1GgMG"
      },
      "source": [
        "ft_num = set([ft for ft in features if feature_clf[ft] == 'num']).intersection(significant_features)\n",
        "\n",
        "def assign_val2bin(value, bins):\n",
        "    if value <= bins[0].left:\n",
        "        return 0\n",
        "    for bin_index, bin in enumerate(bins):\n",
        "        if value in bin:\n",
        "            return bin_index\n",
        "    return len(bins) - 1\n",
        "\n",
        "def assign_bins(df, binning_intervals):\n",
        "  for ft in df.columns:\n",
        "      if ft in binning_intervals:\n",
        "          df[ft] = df[ft].apply(lambda x: assign_val2bin(x, binning_intervals[ft]))\n",
        "  return df"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKgFWn0H1LPt"
      },
      "source": [
        "#### Basic binning: Quantiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBBKsJEdxrE5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "cc0f0e73-c886-45c4-e11c-14930efbb9f4"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "binning_intervals = {}\n",
        "for ft in ft_num:\n",
        "    tmp = pd.qcut(df_train_reprocessed[ft], q=max_bins, duplicates='drop')\n",
        "    binning_intervals[ft] = tmp.unique().tolist()\n",
        "    df_train_reprocessed[ft] = pd.qcut(df_train_reprocessed[ft], q=max_bins, labels=range(len(binning_intervals[ft])), duplicates='drop')\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nbinning_intervals = {}\\nfor ft in ft_num:\\n    tmp = pd.qcut(df_train_reprocessed[ft], q=max_bins, duplicates='drop')\\n    binning_intervals[ft] = tmp.unique().tolist()\\n    df_train_reprocessed[ft] = pd.qcut(df_train_reprocessed[ft], q=max_bins, labels=range(len(binning_intervals[ft])), duplicates='drop')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07u4DCBJGRfv"
      },
      "source": [
        "#### Sick population's Quantiles + Aggregation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC6tZh36GeJD"
      },
      "source": [
        "df_true = df_train_reprocessed[df_train_reprocessed['class'] == 1]\n",
        "df_false = df_train_reprocessed[df_train_reprocessed['class'] == 0]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWa_xHzxGeRy"
      },
      "source": [
        "continuous_bins = {ft: pd.qcut(df_true[ft], q=max_bins, duplicates='drop').values.categories for ft in ft_num}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94fRQTYvGo87"
      },
      "source": [
        "df_bins = assign_bins(df_train_reprocessed, continuous_bins)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Qix1GsHEhD"
      },
      "source": [
        "def compute_aggr_cont_bins(df, cont_bins):\n",
        "    new_cont_bins = {}\n",
        "    for feature in ft_num:\n",
        "        contingency_table = contingency_table = pd.concat([df[feature], df[target]], axis=1).pivot_table(index=feature, columns=target, aggfunc=len).fillna(0).copy().astype(int)\n",
        "        aggregated_cont, aggregated_cont_index = get_aggregated_modalities(contingency_table)\n",
        "        if len(aggregated_cont) < len(cont_bins[feature]):\n",
        "            new_cont_bins[feature] = aggregated_cont\n",
        "    return new_cont_bins"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6hNxZGOGt45",
        "outputId": "ed33dfee-25da-437a-bddb-0837b33d9f17"
      },
      "source": [
        "new_cont_bins = compute_aggr_cont_bins(df_bins, continuous_bins)\n",
        "print(f'Number of continuous variables with aggregated modalities: {len(new_cont_bins)}/{len(ft_num)}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of continuous variables with aggregated modalities: 8/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFCdz5ovHtAQ"
      },
      "source": [
        "df_aggr_bins, new_cont_dict = reduce_mod_features(df_bins.copy(deep=True), new_cont_bins)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hla1QQ-s1Qqh"
      },
      "source": [
        "### Binarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy7UGsW0xrE6"
      },
      "source": [
        "def binarize_ordinal(df):\n",
        "    df_binary = pd.DataFrame([])\n",
        "    for ft in df.columns:\n",
        "        n_cols = df[ft].nunique() - 1\n",
        "        ft_cols = np.zeros((df.shape[0], n_cols))\n",
        "        df_binary[[f\"{ft}_{index}\" for index in range(n_cols)]] = df[ft].apply(lambda x: pd.Series([int(x>index) for index in range(n_cols)]))\n",
        "    return df_binary\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le2tO8VnxrE6"
      },
      "source": [
        "df_train_reprocessed = df_aggr_bins.astype(int)\n",
        "df_train_binary = binarize_ordinal(df_train_reprocessed)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzgWoV3qCnk_"
      },
      "source": [
        "## Format/Convert testing split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFVdPkV8CsXg",
        "outputId": "8b6854be-9266-4f67-8062-a5481c5ab7c9"
      },
      "source": [
        "# Statistically significant features\n",
        "print(f'Original test df: {df_test.shape}')\n",
        "df_test = df_test[significant_features + ['class']]\n",
        "print(f'Filter out non-significant features: {df_test.shape}')\n",
        "# Modalities aggregation\n",
        "df_test_reprocessed, _ = reduce_mod_features(df_test.copy(deep=True), new_mod_bins)\n",
        "print(f'Reduced modalities: {df_test_reprocessed.shape}')\n",
        "# Binning\n",
        "## Continuous variables\n",
        "df_test_bins = assign_bins(df_test_reprocessed, continuous_bins)\n",
        "print(f'Assign continuous bins: {df_test_bins.shape}')\n",
        "df_test_bins_cont, _ = reduce_mod_features(df_test_bins.copy(deep=True), new_cont_bins)\n",
        "print(f'Aggregate continuous bins: {df_test_bins_cont.shape}')\n",
        "# Binarizing\n",
        "df_test_bins_cont = df_test_bins_cont.astype(int)\n",
        "df_test_binary = binarize_ordinal(df_test_bins_cont)\n",
        "print(f'Binary: {df_test_binary.shape}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original test df: (63, 23)\n",
            "Filter out non-significant features: (63, 23)\n",
            "Reduced modalities: (63, 23)\n",
            "Assign continuous bins: (63, 23)\n",
            "Aggregate continuous bins: (63, 23)\n",
            "Binary: (63, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN7BBnBaif5g"
      },
      "source": [
        "## Write to CSV files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5k84c-7ikvg"
      },
      "source": [
        "df_train_binary.to_csv(\"/\".join(dataset_path.split(\"/\")[:-1]) + \"/kidney_train.csv\", index=False)\n",
        "df_test_binary.to_csv(\"/\".join(dataset_path.split(\"/\")[:-1]) + \"/kidney_test.csv\", index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-VoS3OHimLb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}